import os
import streamlit as st #  streamlit = Pythonì—ì„œ GUI ìƒì„±
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound
import openai
import side_bar

from PyPDF2 import PdfReader # PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from tempfile import NamedTemporaryFile

from components import tory_firebase

from gtts import gTTS
from dotenv import load_dotenv # OPEN_API_KEY

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€
from langchain.text_splitter import RecursiveCharacterTextSplitter # langchain.text_splitter = PyPDF2ì˜ í…ìŠ¤íŠ¸ë¥¼ chunksë¡œ ë‚˜ëˆ”
from langchain.embeddings.openai import OpenAIEmbeddings # openAIì˜ embedding = ê³„ì‚°í•˜ê³  ë°˜í™˜
from langchain.vectorstores import FAISS # VectorStore = FAISS, Chroma X = VectorStoreì—ì„œ duckdb.DuckDBPyConnection ì ‘ê·¼ ë¶ˆê°€ëŠ¥

# -------

# .env íŒŒì¼ë¡œë¶€í„° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ì‚¬ì´ë“œ ë°” ìƒì„±
side_bar.run_side_bar()


# ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
st.header("AI Toryì™€ ëŒ€í™”í•˜ê¸°! ğŸ’¬")
st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©° í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•´ë³´ì„¸ìš”! ğŸ’¡')
pdf_expander = st.expander('AI Toryì—ê²Œ í•™ìŠµí•  ë™í™” PDFë¥¼ Upload í•´ì£¼ì„¸ìš”', expanded=True)

# PDF íŒŒì¼ ì—…ë¡œë“œ ë° ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
pdf = st.file_uploader(label=' ', type='pdf', key='pdf')

# PDFê°€ ì—…ë¡œë“œë˜ì—ˆë‹¤ë©´ PDF ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤
if pdf is not None:
    pdf_reader = PdfReader(pdf)
    text = ""


    # ì—…ë¡œë“œí•œ PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    for page in pdf_reader.pages:
        text += page.extract_text()

    # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text=text)

    # PDF íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì €ì¥ì†Œ ìƒì„± ë˜ëŠ” ë¡œë“œ
    store_name = pdf.name[:-4]

    if os.path.exists(f"pdfs/{store_name}.pkl"):
        with open(f"pdfs/{store_name}.pkl", "rb") as f:
            VectorStore = pickle.load(f)
        print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ìˆìŠµë‹ˆë‹¤!")
    else:
        embedding = OpenAIEmbeddings()
        VectorStore = FAISS.from_texts(chunks, embedding=embedding)
        with open(f"pdfs/{store_name}.pkl", "wb") as f:
            pickle.dump(VectorStore, f)
        print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ì—†ìŠµë‹ˆë‹¤!")

    st.session_state.pdf_processed = True  # PDF ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŒì„ í‘œì‹œ

    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if 'chat_generated' not in st.session_state:
        st.session_state['chat_generated'] = []

    if 'chat_past' not in st.session_state:
        st.session_state['chat_past'] = []



    # PDFê°€ ì—…ë¡œë“œë˜ì—ˆë‹¤ë©´ ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤

    gpt_prompt = [{
            "role" : "system", 
            "content" : f"You are a great painter in the van Gogh style that children like. Summarize the contents so that you can make the cover of the book. It's cute and draws children to like."
    }]
    gpt_prompt.append({
            "role" : "user",
            "content" :f"{pdf.name} {text}"
    })

    AIdalleButton = st.button("ğŸ¨")
    if AIdalleButton:
        with st.spinner("í† ë¦¬ê°€ ë™í™”ì˜ í‘œì§€ë¥¼ ìƒìƒí•˜ê³  ìˆì–´ìš”.."):
                gpt_response = openai.ChatCompletion.create(
                    model="gpt-3.5-turbo-16k",
                    messages=gpt_prompt,
                    max_tokens=50
                )

        pic_prompt = gpt_response["choices"][0]["message"]["content"]
        dalle_prompt = pic_prompt

        with st.spinner("í† ë¦¬ê°€ ë™í™”ì˜ í‘œì§€ë¥¼ ê·¸ë ¤ì¤„ê²Œìš”.."):
            dallE_response = openai.Image.create(
                prompt=dalle_prompt,
                size= "1024x1024",
                n=1
            )
        col1, col2, col3 = st.columns(3)
        with col2:
            st.image(dallE_response["data"][0]["url"], caption=pdf.name)
            st.empty()
            st.empty()
    
    query = st.text_input("AIí† ë¦¬ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")
    AIttsButton = st.button("ğŸ”Š")

    if query:
        # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        docs = VectorStore.similarity_search(query=query, k=3)


        # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
        prompt = f"""
            {pdf.name} = í•™ìŠµëœ ë™í™”ì˜ ì œëª©
            {text} = í•™ìŠµëœ ë™í™”ì˜ ë‚´ìš©
            [ì˜ˆì™¸]
            - ì €ëŠ” {pdf.name}ë¼ëŠ” ë™í™”ë¥¼ í•™ìŠµí–ˆì–´ìš”. ëª¨ë¥´ê² ì–´ìš”..

            -----

            [í•™ìŠµ ì •ë³´]
            - {text}

            -----

            [ê·œì¹™]
            - ì—­í• ë†€ì´
            - ì €ëŠ” í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
            - {pdf.name}ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
            - ì˜¤ì§ [í•™ìŠµ ì •ë³´]ì—ì„œ ë°°ìš´ ë‚´ìš©ë§Œ ë‹µí•˜ì„¸ìš”. 
            - ë§ˆì¹˜ ì–´ë¦° ì•„ì´ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¹œì ˆí•œ ì–´ì¡°ì™€ ê°„ë‹¨í•œ ë‹¨ì–´ë¡œ ì‘ì„±

            -----

            ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {pdf.name} ë™í™”ì— ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. 
            [ì˜ˆì™¸], [í•™ìŠµ ì •ë³´], [ê·œì¹™]ì€ ë‹µë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.
            AI Toryê°€ [í•™ìŠµì •ë³´]ì— ëŒ€í•œ ì •ë³´ë¡œ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
            ë‹¹ì‹ ì€ ì˜¤ì§ í•™ìŠµëœ ë‚´ìš©ë§Œ ì•Œë ¤ì£¼ë©° [ê·œì¹™]ì„ ë¬´ì¡°ê±´ ë”°ë¥´ëŠ” AI Toryì…ë‹ˆë‹¤.
            ì§ˆë¬¸í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ [í•™ìŠµ ì •ë³´]ë¡œ í•™ìŠµëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼í•©ë‹ˆë‹¤. 
            [ì˜ˆì‹œ ë¬¸ì¥]ê³¼ [í•™ìŠµ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ [í•™ìŠµ ì •ë³´]ì— ìˆëŠ” ì •ë³´ ë©”ì‹œì§€ë¥¼ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
        """

        user_question = prompt + query

        # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
        with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
            llm = OpenAI(
                temperature=0.1,
                model_name="gpt-3.5-turbo-16k",
                top_p=1,
                max_tokens=1000,
            )

            chain = load_qa_chain(llm=llm, chain_type="stuff") 
            response = chain.run(input_documents=docs, question=user_question)

            bot_message = response
            output = bot_message

            st.session_state.chat_past.append(query)
            st.session_state.chat_generated.append(output)

        # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥
        with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
            if st.session_state['chat_generated']:
                for i in range(len(st.session_state['chat_generated']) - 1, -1, -1):
                    message(st.session_state['chat_past'][i], is_user=True, key=str(i) + '_user', avatar_style="thumbs", seed="Aneka")
                    message(st.session_state["chat_generated"][i], key=str(i), avatar_style="thumbs", seed="Felix")

                if AIttsButton:
                    tts = gTTS(text=output, lang='ko')
                    temp_file = NamedTemporaryFile(delete=False)
                    tts.save(temp_file.name)
                    playsound.playsound(temp_file.name)
                    temp_file.close()
        tory_firebase.add_firebase_chat(query, bot_message)