import os
import streamlit as st #  streamlit = Pythonì—ì„œ GUI ìƒì„±
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound
import openai
import pyaudio
import wave

from side_bar import run_side_bar, set_bg_hack 

from PyPDF2 import PdfReader # PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from tempfile import NamedTemporaryFile

from components import tory_firebase

from gtts import gTTS
from dotenv import load_dotenv # OPEN_API_KEY

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€
from langchain.text_splitter import RecursiveCharacterTextSplitter # langchain.text_splitter = PyPDF2ì˜ í…ìŠ¤íŠ¸ë¥¼ chunksë¡œ ë‚˜ëˆ”
from langchain.embeddings.openai import OpenAIEmbeddings # openAIì˜ embedding = ê³„ì‚°í•˜ê³  ë°˜í™˜
from langchain.vectorstores import FAISS # VectorStore = FAISS, Chroma X = VectorStoreì—ì„œ duckdb.DuckDBPyConnection ì ‘ê·¼ ë¶ˆê°€ëŠ¥
# -------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
pdf_image_path = "pages/images/tory_pdf.png" 
main_bg_ext = "pages/images/tory_back.png"

set_bg_hack(main_bg_ext)
st.write( """
        <style>
        .st-bd {
            background-color: rgba(255, 255, 255);
            border-radius: 15px; 
            padding: 30px; 
            box-shadow: 5px 5px 5px rgba(0, 0, 0, 0.2); 
        }
        </style>
        """,
    unsafe_allow_html=True)

# ì‚¬ì´ë“œ ë°” ìƒì„±
pdf, text, VectorStore = run_side_bar()
sample_rate = 44100  # ì˜¤ë””ì˜¤ ìƒ˜í”Œ ì†ë„
duration = 6  # ë…¹ìŒ ì‹œê°„ (ì´ˆ)
tab1, tab2 = st.tabs([" ", " "])

with tab1:
    if pdf is None:
        # ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
        st.header("AI Toryì™€ ì—­í• ë†€ì´ í•˜ê¸°! ğŸ•¹ï¸")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì—­í• ì„ ì…ë ¥í•˜ê³  ì—­í• ë†€ì´ë¥¼ í•´ë´ìš”! ğŸ«µğŸ»')
        st.image(pdf_image_path)

    if pdf is not None:
        st.header(f"AIToryì™€ {pdf.name} ì—­í• ë†€ì´ ğŸ•¹ï¸")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì—­í• ì„ ì…ë ¥í•˜ê³  ì—­í• ë†€ì´ë¥¼ í•´ë´ìš”! ğŸ«µğŸ»')
    if pdf is not None:
        user = ""
        ai = ""

        # ì‚¬ìš©ì ë° AI ì—­í•  ì…ë ¥
        with st.expander(' ', expanded=True):
            user_input_col, ai_input_col = st.columns(2)
            user_input = user_input_col.text_input("ì‚¬ìš©ìì˜ ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš” :")
            ai_input = ai_input_col.text_input("AI Toryì˜ ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš” :")

            if not user_input or not ai_input:
                st.warning("ì—­í• ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        col5, col6, col7 = st.columns(3)

        if user_input and ai_input:  # ì—­í• ì´ ëª¨ë‘ ì…ë ¥ëœ ê²½ìš°ì—ë§Œ ì•„ë˜ ì»¨í…Œì´ë„ˆ í‘œì‹œ

            # ìŠ¤íŠ¸ë¦¼ë¦¿ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.container():
                with st.form(key='role_form', clear_on_submit=True):
                    query = st.text_input(' ',  placeholder="Send a message", value="")
                    col5, col6, col7 = st.columns(3)

                    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
                    with col1:
                        submit = st.form_submit_button(label="Send")
                    with col2:
                        whisper_button = st.form_submit_button("ğŸ™ï¸", help="ë§ˆì´í¬ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”.")
                    with col3:
                        tts_button = st.checkbox("ğŸ”Š",  value=False, help="AIí† ë¦¬ê°€ ë§í•´ì¤„ê²Œìš”.")
                    with col4:
                        toggle_state = st.checkbox('AI ğŸ¨', value=True, help="AIí† ë¦¬ê°€ ê·¸ë¦¼ì„ ê·¸ë ¤ì¤„ê²Œìš”.")

                if whisper_button:
                    with st.spinner("ë§í•´ì£¼ì„¸ìš”! í† ë¦¬ê°€ ë“£ê³ ìˆì–´ìš”..."):
                        # PyAudioë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
                        audio_data = []
                        p = pyaudio.PyAudio()
                        stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)

                        # ì˜¤ë””ì˜¤ ë°ì´í„° ë…¹ìŒ
                        for i in range(0, int(sample_rate / 1024 * duration)):
                            audio_chunk = stream.read(1024)
                            audio_data.append(audio_chunk)

                    with st.spinner("í† ë¦¬ê°€ ë‹¤ ë“¤ì—ˆì–´ìš”..."):
                        # ë…¹ìŒ ì¤‘ì§€
                        stream.stop_stream()
                        stream.close()
                        p.terminate()

                        # ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì˜µì…˜)
                        audio_file = "recorded_audio.wav"
                        with wave.open(audio_file, "wb") as wf:
                            wf.setnchannels(1)
                            wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
                            wf.setframerate(sample_rate)
                            wf.writeframes(b"".join(audio_data))

                        # ìˆ˜ì •ëœ ë¶€ë¶„: ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°
                        with open("recorded_audio.wav", "rb") as audio_file:
                            transcript = openai.Audio.transcribe("whisper-1", audio_file)
                            ko_response = transcript["text"].encode('utf-16').decode('utf-16')
                            query = ko_response
                # PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                pdf_reader = PdfReader(pdf)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text()

                # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000,
                    chunk_overlap=200,
                    length_function=len
                )
                chunks = text_splitter.split_text(text=text)

                # PDF íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì €ì¥ì†Œ ìƒì„± ë˜ëŠ” ë¡œë“œ
                store_name = pdf.name[:-4]

                if os.path.exists(f"pdfs/{store_name}.pkl"):
                    with open(f"pdfs/{store_name}.pkl", "rb") as f:
                        VectorStore = pickle.load(f)
                    print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ìˆìŠµë‹ˆë‹¤!")
                else:
                    embedding = OpenAIEmbeddings()
                    VectorStore = FAISS.from_texts(chunks, embedding=embedding)
                    with open(f"pdfs/{store_name}.pkl", "wb") as f:
                        pickle.dump(VectorStore, f)
                    print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ì—†ìŠµë‹ˆë‹¤!")

                # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
                if 'role_generated' not in st.session_state:
                    st.session_state['role_generated'] = []

                if 'role_past' not in st.session_state:
                    st.session_state['role_past'] = []

                if query:
                    # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
                    docs = VectorStore.similarity_search(query=query, k=3)
                    user = user_input
                    ai = ai_input
                    print(user)

                    # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
                    prompt = f"""
                    ë„ˆ = {user}
                    ë‚˜ = {ai}
                    ì‚¬ìš©ìì˜ ì§ˆë¬¸ = {query}

                    ----------------------------------------------------------------

                    [ì˜ˆì‹œë¬¸ì¥]
                    - ë‹¹ì‹ ì€ {user}ì´ê³ , ì €ëŠ” {ai}ì…ë‹ˆë‹¤.
                    - ê·¸ê²ƒì— ëŒ€í•œ ì •ë³´ëŠ” ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
                    
                    ----------------------------------------------------------------
                    [ê·œì¹™]
                    - {user}ì˜ {query}ì— {ai}ì˜ ë‹µë³€ì„ ìµœëŒ€ 3ì¤„ë¡œ í•´ë¼.
                    - {user}ì˜ {query}ì™€ {ai}ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ í•´ë¼.
                    - {user}ì™€ {ai}ì˜ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”.
                    - {user}ê°€ ì§€ì •í•œ {ai}ì— ëŒ€í•œ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš° ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•´.
                    - ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì§€ì •í•œ ì—­í• ì¸ {ai}ì¸ ê²ƒ ì²˜ëŸ¼ ëŒ€ë‹µí•˜ê³  í–‰ë™í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
                    ----------------------------------------------------------------
                    ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {ai}ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. [ì˜ˆì‹œ ë¬¸ì¥]ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´, ì—­í• ë†€ì´ì— ëŒ€ë‹µí•œ ë‚´ìš©ì…ë‹ˆë‹¤.
                    [ê·œì¹™]ì„ ë”°ë¥´ëŠ” {ai}ì…ë‹ˆë‹¤. {user}ì—ê²Œ {ai}ë§Œì˜ ë‹µë³€ì„ í•˜ì„¸ìš”.
                    ----------------------------------------------------------------
                    """

                    user_question = prompt + query

                    # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
                    with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
                        llm = OpenAI(
                            temperature=0.1,
                            model_name="gpt-3.5-turbo-16k",
                            top_p=1,
                        )
                        chain = load_qa_chain(llm=llm, chain_type="refine")
                        response = chain.run(input_documents=docs, question=user_question)

                        bot_message = response
                        output = bot_message

                        st.session_state.role_past.append(query)
                        st.session_state.role_generated.append(output)

                    if toggle_state:
                            query = ""
                            # PDFê°€ ì—…ë¡œë“œë˜ì—ˆë‹¤ë©´ PDF ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤
                            gpt_prompt = [{
                                    "role" : "system", 
                                    "content" : f"You are Beatrix Potter. Choose a character and darw a cute and lovely, kids-like picture around that character."
                            }]
                            gpt_prompt.append({
                                    "role" : "user",
                                    "content" :f"{pdf.name}, {text}"
                            })

                            with st.spinner("í† ë¦¬ê°€ ë™í™”ë¥¼ ìƒìƒí•˜ê³  ìˆì–´ìš”.."):
                                    gpt_response = openai.ChatCompletion.create(
                                        model="gpt-3.5-turbo-16k",
                                        messages=gpt_prompt,
                                        max_tokens=50
                                    )

                            pic_prompt = gpt_response["choices"][0]["message"]["content"]
                            dalle_prompt = pic_prompt

                            with st.spinner("í† ë¦¬ê°€ ë™í™”ì— ëŒ€í•´ì„œ ê·¸ë ¤ì¤„ê²Œìš”.."):
                                dallE_response = openai.Image.create(
                                    prompt=dalle_prompt,
                                    size= "1024x1024",
                                    n=1
                                )
                            with col6:
                                img = st.image(dallE_response["data"][0]["url"], caption=pdf.name)
                                st.empty()
                                st.empty()
                    # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥
                    with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
                        if st.session_state['role_generated']:
                            for i in range(len(st.session_state['role_generated']) - 1, -1, -1):
                                message(st.session_state["role_generated"][i], key=str(i), avatar_style="thumbs", seed="Felix")
                                message(st.session_state['role_past'][i], is_user=True, key=str(i) + '_user', avatar_style="thumbs", seed="Aneka")

                            if tts_button:
                                query = ""
                                tts = gTTS(text=output, lang='ko')
                                temp_file = NamedTemporaryFile(delete=False)
                                tts.save(temp_file.name)
                                playsound.playsound(temp_file.name)
                                temp_file.close()

                        tory_firebase.add_firebase_role(query, bot_message)