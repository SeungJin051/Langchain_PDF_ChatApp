import os
#  streamlit = Pythonì—ì„œ GUI ìƒì„±
import streamlit as st
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound

from tempfile import NamedTemporaryFile

from gtts import gTTS
from dotenv import load_dotenv # OPEN_API_KEY

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

# PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from PyPDF2 import PdfReader

# langchain.text_splitter = PyPDF2ì˜ í…ìŠ¤íŠ¸ë¥¼ chunksë¡œ ë‚˜ëˆ”
from langchain.text_splitter import RecursiveCharacterTextSplitter
# openAIì˜ embedding = ê³„ì‚°í•˜ê³  ë°˜í™˜
from langchain.embeddings.openai import OpenAIEmbeddings
# VectorStore = FAISS, Chroma X = VectorStoreì—ì„œ duckdb.DuckDBPyConnection ì ‘ê·¼ ë¶ˆê°€ëŠ¥
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€

import side_bar
from components import tory_firebase

# .env íŒŒì¼ë¡œë¶€í„° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì‚¬ì´ë“œ ë°” ìƒì„±
side_bar.run_side_bar()

# ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
st.header("AI Toryì™€ ëŒ€í™”í•˜ê¸°! ğŸ’¬")

# PDF íŒŒì¼ ì—…ë¡œë“œ ë° ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
pdf = st.file_uploader("AI Toryì—ê²Œ í•™ìŠµí•  ë™í™” PDFë¥¼ Upload í•´ì£¼ì„¸ìš”", type='pdf', key='pdf')

if pdf is not None:
    query = st.text_input("AIí† ë¦¬ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")

    AIttsButton = st.button("ğŸ”Š")
    pdf_reader = PdfReader(pdf)
    text = ""

    # ì—…ë¡œë“œí•œ PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    for page in pdf_reader.pages:
        text += page.extract_text()

    # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text=text)

    # PDF íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì €ì¥ì†Œ ìƒì„± ë˜ëŠ” ë¡œë“œ
    store_name = pdf.name[:-4]

    if os.path.exists(f"pdfs/{store_name}.pkl"):
        with open(f"pdfs/{store_name}.pkl", "rb") as f:
            VectorStore = pickle.load(f)
        print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ìˆìŠµë‹ˆë‹¤!")
    else:
        embedding = OpenAIEmbeddings()
        VectorStore = FAISS.from_texts(chunks, embedding=embedding)
        with open(f"pdfs/{store_name}.pkl", "wb") as f:
            pickle.dump(VectorStore, f)
        print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ì—†ìŠµë‹ˆë‹¤!")

    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if 'generated' not in st.session_state:
        st.session_state['generated'] = []

    if 'past' not in st.session_state:
        st.session_state['past'] = []

    if query:
        # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
        docs = VectorStore.similarity_search(query=query, k=3)

        # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
        prompt = f"""
            {pdf.name} = í•™ìŠµëœ ë™í™”ì˜ ì œëª©
            {text} = í•™ìŠµëœ ë™í™”ì˜ ë‚´ìš©
            [ì˜ˆì™¸]
            - ì €ëŠ” {pdf.name}ë¼ëŠ” ë™í™”ë¥¼ í•™ìŠµí–ˆì–´ìš”. ëª¨ë¥´ê² ì–´ìš”..

            -----

            [í•™ìŠµ ì •ë³´]
            - {text}

            -----

            [ê·œì¹™]
            - ì—­í• ë†€ì´
            - ì €ëŠ” í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
            - {pdf.name}ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
            - ì˜¤ì§ [í•™ìŠµ ì •ë³´]ì—ì„œ ë°°ìš´ ë‚´ìš©ë§Œ ë‹µí•˜ì„¸ìš”. 
            - ë§ˆì¹˜ ì–´ë¦° ì•„ì´ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¹œì ˆí•œ ì–´ì¡°ì™€ ê°„ë‹¨í•œ ë‹¨ì–´ë¡œ ì‘ì„±

            -----

            ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {pdf.name} ë™í™”ì— ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. 
            [ì˜ˆì™¸], [í•™ìŠµ ì •ë³´], [ê·œì¹™]ì€ ë‹µë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.
            AI Toryê°€ [í•™ìŠµì •ë³´]ì— ëŒ€í•œ ì •ë³´ë¡œ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
            ë‹¹ì‹ ì€ ì˜¤ì§ í•™ìŠµëœ ë‚´ìš©ë§Œ ì•Œë ¤ì£¼ë©° [ê·œì¹™]ì„ ë¬´ì¡°ê±´ ë”°ë¥´ëŠ” AI Toryì…ë‹ˆë‹¤.
            ì§ˆë¬¸í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ [í•™ìŠµ ì •ë³´]ë¡œ í•™ìŠµëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼í•©ë‹ˆë‹¤. 
            [ì˜ˆì‹œ ë¬¸ì¥]ê³¼ [í•™ìŠµ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ [í•™ìŠµ ì •ë³´]ì— ìˆëŠ” ì •ë³´ ë©”ì‹œì§€ë¥¼ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
        """

        user_question = prompt + query

        # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
        with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
            llm = OpenAI(
                temperature=0.1,
                model_name="gpt-3.5-turbo-16k",
                top_p=1,
                max_tokens=1000
            )

            chain = load_qa_chain(llm=llm, chain_type="stuff")
            response = chain.run(input_documents=docs, question=user_question)

            bot_message = response
            output = bot_message


            st.session_state.past.append(query)
            st.session_state.generated.append(output)

        # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥
        with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
            if st.session_state['generated']:
                for i in range(len(st.session_state['generated']) - 1, -1, -1):
                    message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
                    message(st.session_state["generated"][i], key=str(i))

                if AIttsButton:
                    tts = gTTS(text=output, lang='ko')
                    temp_file = NamedTemporaryFile(delete=False)
                    tts.save(temp_file.name)
                    playsound.playsound(temp_file.name)
                    temp_file.close()
        tory_firebase.add_firebase(query, bot_message)