import os
import streamlit as st #  streamlit = Pythonì—ì„œ GUI ìƒì„±
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound
import openai
from side_bar import run_side_bar

from PyPDF2 import PdfReader # PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from tempfile import NamedTemporaryFile

from components import tory_firebase

from gtts import gTTS
from dotenv import load_dotenv # OPEN_API_KEY

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€
from langchain.text_splitter import RecursiveCharacterTextSplitter # langchain.text_splitter = PyPDF2ì˜ í…ìŠ¤íŠ¸ë¥¼ chunksë¡œ ë‚˜ëˆ”
from langchain.embeddings.openai import OpenAIEmbeddings # openAIì˜ embedding = ê³„ì‚°í•˜ê³  ë°˜í™˜
from langchain.vectorstores import FAISS # VectorStore = FAISS, Chroma X = VectorStoreì—ì„œ duckdb.DuckDBPyConnection ì ‘ê·¼ ë¶ˆê°€ëŠ¥

# -------

# .env íŒŒì¼ë¡œë¶€í„° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
pdf_image_path = "pages/images/download-pdf.gif" 

# ì‚¬ì´ë“œ ë°” ìƒì„±
pdf, text, VectorStore = run_side_bar()

if pdf is None:
    # ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
    st.header("AI Toryì™€ ì—­í• ë†€ì´ í•˜ê¸°! ğŸ•¹ï¸")
    st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì—­í• ì„ ì…ë ¥í•˜ê³  ì—­í• ë†€ì´ë¥¼ í•´ë´ìš”! ğŸ«µğŸ»')
    st.info("PDFë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”...")
    st.image(pdf_image_path)

if pdf is not None:
    st.header(f"AIToryì™€ {pdf.name} ì—­í• ë†€ì´ ğŸ•¹ï¸")
    st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì—­í• ì„ ì…ë ¥í•˜ê³  ì—­í• ë†€ì´ë¥¼ í•´ë´ìš”! ğŸ«µğŸ»')
if pdf is not None:
    user = ""
    ai = ""

    # ì‚¬ìš©ì ë° AI ì—­í•  ì…ë ¥
    with st.expander('ì—­í• ì„ ì •í•´ì£¼ì„¸ìš”!', expanded=True):
        user_input_col, ai_input_col = st.columns(2)
        user_input = user_input_col.text_input("ì‚¬ìš©ìì˜ ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš”:")
        ai_input = ai_input_col.text_input("AI Toryì˜ ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš”:")

        if not user_input or not ai_input:
            st.warning("ì—­í• ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    if user_input and ai_input:  # ì—­í• ì´ ëª¨ë‘ ì…ë ¥ëœ ê²½ìš°ì—ë§Œ ì•„ë˜ ì»¨í…Œì´ë„ˆ í‘œì‹œ
        st.markdown("<hr>", unsafe_allow_html=True)

        # ìŠ¤íŠ¸ë¦¼ë¦¿ ì»¨í…Œì´ë„ˆ ìƒì„±
        with st.container():
            # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
            query = st.text_input("AIí† ë¦¬ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")

            # ìŒì„± ë“£ê¸° ë° ì „ì†¡ ë²„íŠ¼ ìƒì„±
            AIttsButton = st.button("ğŸ”Š")
            
            # PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            pdf_reader = PdfReader(pdf)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text()

            # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                length_function=len
            )
            chunks = text_splitter.split_text(text=text)

            # PDF íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì €ì¥ì†Œ ìƒì„± ë˜ëŠ” ë¡œë“œ
            store_name = pdf.name[:-4]

            if os.path.exists(f"pdfs/{store_name}.pkl"):
                with open(f"pdfs/{store_name}.pkl", "rb") as f:
                    VectorStore = pickle.load(f)
                print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ìˆìŠµë‹ˆë‹¤!")
            else:
                embedding = OpenAIEmbeddings()
                VectorStore = FAISS.from_texts(chunks, embedding=embedding)
                with open(f"pdfs/{store_name}.pkl", "wb") as f:
                    pickle.dump(VectorStore, f)
                print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ì—†ìŠµë‹ˆë‹¤!")

            # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
            if 'role_generated' not in st.session_state:
                st.session_state['role_generated'] = []

            if 'role_past' not in st.session_state:
                st.session_state['role_past'] = []

            if query:
                # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
                docs = VectorStore.similarity_search(query=query, k=3)
                user = user_input
                ai = ai_input
                print(user)

                # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
                prompt = f"""
                {user} = ìƒëŒ€ë°©
                {ai} = ë‚˜
                {query} = ì‚¬ìš©ìì˜ ì§ˆë¬¸  

                ----------------------------------------------------------------

                [ì˜ˆì‹œë¬¸ì¥]
                - ì €ëŠ” ë°±ì„¤ê³µì£¼ì…ë‹ˆë‹¤.
                - ë‹¹ì‹ ì€ ì™•ìì…ë‹ˆë‹¤.
                - ê·¸ê²ƒì— ëŒ€í•œ ì •ë³´ëŠ” ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
                
                ----------------------------------------------------------------
                [ê·œì¹™]
                - {user}ì˜ {query}ì— {ai}ì˜ ë‹µë³€ì„ ìµœëŒ€ 3ì¤„ë¡œ í•´ë¼.
                - {user}ì˜ {query}ì™€ {ai}ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ í•´ë¼.
                - {user}ì™€ {ai}ì˜ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”.
                - {user}ê°€ ì§€ì •í•œ {ai}ì— ëŒ€í•œ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš° ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•´.
                - ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì§€ì •í•œ ì—­í• ì¸ {ai}ì¸ ê²ƒ ì²˜ëŸ¼ ëŒ€ë‹µí•˜ê³  í–‰ë™í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
                ----------------------------------------------------------------
                ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {ai}ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. [ì˜ˆì‹œ ë¬¸ì¥]ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´, ì—­í• ë†€ì´ì— ëŒ€ë‹µí•œ ë‚´ìš©ì…ë‹ˆë‹¤.
                [ê·œì¹™]ì„ ë”°ë¥´ëŠ” {ai}ì…ë‹ˆë‹¤. {user}ì—ê²Œ {ai}ë§Œì˜ ë‹µë³€ì„ í•˜ì„¸ìš”.
                ----------------------------------------------------------------
                """

                user_question = prompt + query

                # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
                with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
                    llm = OpenAI(
                        temperature=0.1,
                        model_name="gpt-3.5-turbo-16k",
                        top_p=1,
                    )
                    chain = load_qa_chain(llm=llm, chain_type="refine")
                    response = chain.run(input_documents=docs, question=user_question)

                    bot_message = response
                    output = bot_message

                    st.session_state.role_past.append(query)
                    st.session_state.role_generated.append(output)

                # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥
                with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
                    if st.session_state['role_generated']:
                        for i in range(len(st.session_state['role_generated']) - 1, -1, -1):
                            message(st.session_state["role_generated"][i], key=str(i), avatar_style="thumbs", seed="Felix")
                            message(st.session_state['role_past'][i], is_user=True, key=str(i) + '_user', avatar_style="thumbs", seed="Aneka")

                        if AIttsButton:
                            tts = gTTS(text=output, lang='ko')
                            temp_file = NamedTemporaryFile(delete=False)
                            tts.save(temp_file.name)
                            playsound.playsound(temp_file.name)
                            temp_file.close()
                    tory_firebase.add_firebase_role(query, bot_message)