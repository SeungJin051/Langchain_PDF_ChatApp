import os
import streamlit as st #  streamlit = Pythonì—ì„œ GUI ìƒì„±
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound
import openai
import pyaudio
import wave

from side_bar import run_side_bar, set_bg_hack 

from PyPDF2 import PdfReader # PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from tempfile import NamedTemporaryFile

from components import tory_firebase

from gtts import gTTS
from dotenv import load_dotenv # OPEN_API_KEY

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€
# -------
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
pdf_image_path = "pages/images/tory_pdf.png" 
main_bg_ext = "pages/images/tory_back.png"

set_bg_hack(main_bg_ext)
st.write( """
        <style>
        .st-bd {
            background-color: rgba(255, 255, 255);
            border-radius: 15px; 
            padding: 30px; 
            box-shadow: 5px 5px 5px rgba(0, 0, 0, 0.2); 
        }
        </style>
        """,
    unsafe_allow_html=True)

# ì‚¬ì´ë“œ ë°” ìƒì„±
pdf, text, VectorStore = run_side_bar()
sample_rate = 44100  # ì˜¤ë””ì˜¤ ìƒ˜í”Œ ì†ë„
duration = 6  # ë…¹ìŒ ì‹œê°„ (ì´ˆ)
tab1, tab2 = st.tabs([" ", " "])
with tab1:
    if pdf is None:
        # ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
        st.header("AI Toryì™€ ëŒ€í™”í•˜ê¸°! ğŸ’¬")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©° í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•´ë³´ì„¸ìš”! ğŸ’¡')
        st.image(pdf_image_path)

    if pdf is not None:
        st.header(f"AIToryì™€ {pdf.name} ğŸ’¬")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©° í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•´ë³´ì„¸ìš”! ğŸ’¡')
            
    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if 'chat_generated' not in st.session_state:
        st.session_state['chat_generated'] = []

    if 'chat_past' not in st.session_state:
        st.session_state['chat_past'] = []

    if 'text' not in st.session_state:
        st.session_state['text'] = []
    
    col1, col2, col3 = st.columns(3)

    if pdf is not None:
        with st.form(key='query_form', clear_on_submit=True):
            query = st.text_input(' ',  placeholder="Send a message", value="")
            col5, col6, col7 = st.columns(3)

            col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
            with col1:
                submit = st.form_submit_button(label="Send")
            with col2:
                whisper_button = st.form_submit_button("ğŸ™ï¸", help="ë§ˆì´í¬ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”.")
            with col3:
                tts_button = st.checkbox("ğŸ”Š",  value=False, help="AIí† ë¦¬ê°€ ë§í•´ì¤„ê²Œìš”.")
            with col4:
                toggle_state = st.checkbox('AI ğŸ¨', value=False, help="AIí† ë¦¬ê°€ ê·¸ë¦¼ì„ ê·¸ë ¤ì¤„ê²Œìš”.")

        if whisper_button:
            with st.spinner("ë§í•´ì£¼ì„¸ìš”! í† ë¦¬ê°€ ë“£ê³ ìˆì–´ìš”..."):
                # PyAudioë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
                audio_data = []
                p = pyaudio.PyAudio()
                stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)

                # ì˜¤ë””ì˜¤ ë°ì´í„° ë…¹ìŒ
                for i in range(0, int(sample_rate / 1024 * duration)):
                    audio_chunk = stream.read(1024)
                    audio_data.append(audio_chunk)

            with st.spinner("í† ë¦¬ê°€ ë‹¤ ë“¤ì—ˆì–´ìš”..."):
                # ë…¹ìŒ ì¤‘ì§€
                stream.stop_stream()
                stream.close()
                p.terminate()

                # ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì˜µì…˜)
                audio_file = "recorded_audio.wav"
                with wave.open(audio_file, "wb") as wf:
                    wf.setnchannels(1)
                    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
                    wf.setframerate(sample_rate)
                    wf.writeframes(b"".join(audio_data))

                # ìˆ˜ì •ëœ ë¶€ë¶„: ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°
                with open("recorded_audio.wav", "rb") as audio_file:
                    transcript = openai.Audio.transcribe("whisper-1", audio_file)
                    ko_response = transcript["text"].encode('utf-16').decode('utf-16')
                    query = ko_response

        if query:
            # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            docs = VectorStore.similarity_search(query=query, k=3)

            # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
            prompt = f"""
                {pdf.name} = í•™ìŠµëœ ë™í™”ì˜ ì œëª©
                {text} = í•™ìŠµëœ ë™í™”ì˜ ë‚´ìš©
                [ì˜ˆì™¸]
                - ì €ëŠ” {pdf.name}ë¼ëŠ” ë™í™”ë¥¼ í•™ìŠµí–ˆì–´ìš”. ëª¨ë¥´ê² ì–´ìš”..

                -----

                [í•™ìŠµ ì •ë³´]
                - {text}

                -----

                [ê·œì¹™]
                - ì €ëŠ” í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
                - {pdf.name}ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
                - ì˜¤ì§ [í•™ìŠµ ì •ë³´]ì—ì„œ ë°°ìš´ ë‚´ìš©ë§Œ ë‹µí•˜ì„¸ìš”. 
                - ë§ˆì¹˜ ì–´ë¦° ì•„ì´ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¹œì ˆí•œ ì–´ì¡°ì™€ ê°„ë‹¨í•œ ë‹¨ì–´ë¡œ ì‘ì„±

                -----

                ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {pdf.name} ë™í™”ì— ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. 
                [ì˜ˆì™¸], [í•™ìŠµ ì •ë³´], [ê·œì¹™]ì€ ë‹µë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.
                AI Toryê°€ [í•™ìŠµì •ë³´]ì— ëŒ€í•œ ì •ë³´ë¡œ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
                ë‹¹ì‹ ì€ ì˜¤ì§ í•™ìŠµëœ ë‚´ìš©ë§Œ ì•Œë ¤ì£¼ë©° [ê·œì¹™]ì„ ë¬´ì¡°ê±´ ë”°ë¥´ëŠ” AI Toryì…ë‹ˆë‹¤.
                ì§ˆë¬¸í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ [í•™ìŠµ ì •ë³´]ë¡œ í•™ìŠµëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼í•©ë‹ˆë‹¤. 
                [ì˜ˆì‹œ ë¬¸ì¥]ê³¼ [í•™ìŠµ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ [í•™ìŠµ ì •ë³´]ì— ìˆëŠ” ì •ë³´ ë©”ì‹œì§€ë¥¼ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
            """

            user_question = prompt + query

            # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
            with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
                llm = OpenAI(
                    temperature=0,
                    model_name="gpt-3.5-turbo-16k",
                    top_p=1,
                    max_tokens=1000,
                )

                chain = load_qa_chain(llm=llm, chain_type="stuff") 
                response = chain.run(input_documents=docs, question=user_question)

                bot_message = response
                output = bot_message

                st.session_state.chat_past.append(query)
                st.session_state.chat_generated.append(output)

            if toggle_state:
                    gpt_prompt = [{
                            "role" : "system", 
                            "content" : f"You are Beatrix Potter. Choose a character in user and draw a cute, kids-like picture around that character."
                    }]
                    gpt_prompt.append({
                            "role" : "user",
                            "content" :f"{pdf.name}, {text}"
                    })

                    with st.spinner("í† ë¦¬ê°€ ë™í™”ë¥¼ ìƒìƒí•˜ê³  ìˆì–´ìš”.."):
                            gpt_response = openai.ChatCompletion.create(
                                model="gpt-3.5-turbo-16k",
                                messages=gpt_prompt,
                                max_tokens=50
                            )

                    pic_prompt = gpt_response["choices"][0]["message"]["content"]
                    dalle_prompt = pic_prompt

                    with st.spinner("í† ë¦¬ê°€ ë™í™”ì— ëŒ€í•´ì„œ ê·¸ë ¤ì¤„ê²Œìš”.."):
                        dallE_response = openai.Image.create(
                            prompt=dalle_prompt,
                            size= "1024x1024",
                            n=1
                        )
                    with col6:
                        img = st.image(dallE_response["data"][0]["url"], caption=pdf.name)
                        st.empty()
                        st.empty()
        

            # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥, tts í† ê¸€ë²„íŠ¼
            with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
                if st.session_state['chat_generated']:
                    for i in range(len(st.session_state['chat_generated']) - 1, -1, -1):
                        message(st.session_state['chat_past'][i], is_user=True, key=str(i) + '_user', avatar_style="thumbs", seed="Aneka")
                        message(st.session_state["chat_generated"][i], key=str(i), avatar_style="thumbs", seed="Felix")
                    
                    if tts_button:
                        tts = gTTS(text=output, lang='ko')
                        temp_file = NamedTemporaryFile(delete=False)
                        tts.save(temp_file.name)
                        playsound.playsound(temp_file.name)
                        temp_file.close()

            tory_firebase.add_firebase_chat(query, bot_message)
