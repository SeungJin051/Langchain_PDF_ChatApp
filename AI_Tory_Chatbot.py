import os
import streamlit as st #  streamlit = Pythonì—ì„œ GUI ìƒì„±
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound
import openai
import pyaudio
import wave

from side_bar import run_side_bar

from PyPDF2 import PdfReader # PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from tempfile import NamedTemporaryFile

from components import tory_firebase

from gtts import gTTS
from dotenv import load_dotenv # OPEN_API_KEY

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€
from langchain.text_splitter import RecursiveCharacterTextSplitter # langchain.text_splitter = PyPDF2ì˜ í…ìŠ¤íŠ¸ë¥¼ chunksë¡œ ë‚˜ëˆ”
from langchain.embeddings.openai import OpenAIEmbeddings # openAIì˜ embedding = ê³„ì‚°í•˜ê³  ë°˜í™˜
from langchain.vectorstores import FAISS # VectorStore = FAISS, Chroma X = VectorStoreì—ì„œ duckdb.DuckDBPyConnection ì ‘ê·¼ ë¶ˆê°€ëŠ¥
# -------

# .env íŒŒì¼ë¡œë¶€í„° í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
thumb_style_image_path = "pages/images/thumb_style.png" 
pdf_image_path = "pages/images/download-pdf.gif" 
# ì‚¬ì´ë“œ ë°” ìƒì„±
pdf, text, VectorStore = run_side_bar()
sample_rate = 44100  # ì˜¤ë””ì˜¤ ìƒ˜í”Œ ì†ë„
duration = 6  # ë…¹ìŒ ì‹œê°„ (ì´ˆ)

tab1, tab2 = st.tabs(["AI Toryì™€ ëŒ€í™”í•˜ê¸°", "AI Toryì—­í• ë†€ì´ í•˜ê¸°"])
with tab1:
    if pdf is None:
        # ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
        st.header("AI Toryì™€ ëŒ€í™”í•˜ê¸°! ğŸ’¬")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©° í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•´ë³´ì„¸ìš”! ğŸ’¡')
        st.image(pdf_image_path)

    if pdf is not None:
        st.header(f"AIToryì™€ {pdf.name} ğŸ’¬")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©° í˜ì‹ ì ì¸ ì•„ì´ë””ì–´ë¥¼ ê³µìœ í•´ë³´ì„¸ìš”! ğŸ’¡')
            
    # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
    if 'chat_generated' not in st.session_state:
        st.session_state['chat_generated'] = []

    if 'chat_past' not in st.session_state:
        st.session_state['chat_past'] = []

    if 'text' not in st.session_state:
        st.session_state['text'] = []
    

    col1, col2, col3 = st.columns(3)

    if pdf is not None:
        query = st.text_input("AIí† ë¦¬ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!", placeholder="Send a message")
        st.session_state.text.append(text)

        # ê°€ë¡œë¡œ ì •ë ¬ëœ ë²„íŠ¼
        btn_col1, btn_col2, btn_col3 = st.columns(3)

        with btn_col1:
            whisper_button = st.button("ğŸ™ï¸", help="ë§ˆì´í¬ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”.")

        with btn_col2:
            tts_button = st.checkbox("ğŸ”Š",  value=True, help="AIí† ë¦¬ê°€ ë§í•´ì¤„ê²Œìš”.")

        with btn_col3:
            toggle_state = st.checkbox('AI ğŸ¨', value=True, help="AIí† ë¦¬ê°€ ê·¸ë¦¼ì„ ê·¸ë ¤ì¤„ê²Œìš”.")


        if whisper_button:
            with st.spinner("ë§í•´ì£¼ì„¸ìš”! í† ë¦¬ê°€ ë“£ê³ ìˆì–´ìš”..."):
                # PyAudioë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
                audio_data = []
                p = pyaudio.PyAudio()
                stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)

                # ì˜¤ë””ì˜¤ ë°ì´í„° ë…¹ìŒ
                for i in range(0, int(sample_rate / 1024 * duration)):
                    audio_chunk = stream.read(1024)
                    audio_data.append(audio_chunk)

            with st.spinner("í† ë¦¬ê°€ ë‹¤ ë“¤ì—ˆì–´ìš”..."):
                # ë…¹ìŒ ì¤‘ì§€
                stream.stop_stream()
                stream.close()
                p.terminate()

                # ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì˜µì…˜)
                audio_file = "recorded_audio.wav"
                with wave.open(audio_file, "wb") as wf:
                    wf.setnchannels(1)
                    wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
                    wf.setframerate(sample_rate)
                    wf.writeframes(b"".join(audio_data))

                # ìˆ˜ì •ëœ ë¶€ë¶„: ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°
                with open("recorded_audio.wav", "rb") as audio_file:
                    transcript = openai.Audio.transcribe("whisper-1", audio_file)
                    ko_response = transcript["text"].encode('utf-16').decode('utf-16')
                    query = ko_response

        if toggle_state is False: 
            with col2:
                img = st.image(thumb_style_image_path, caption="AITory")
                st.empty()
                st.empty()

        if query:
            # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
            docs = VectorStore.similarity_search(query=query, k=3)

            # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
            prompt = f"""
                {pdf.name} = í•™ìŠµëœ ë™í™”ì˜ ì œëª©
                {text} = í•™ìŠµëœ ë™í™”ì˜ ë‚´ìš©
                [ì˜ˆì™¸]
                - ì €ëŠ” {pdf.name}ë¼ëŠ” ë™í™”ë¥¼ í•™ìŠµí–ˆì–´ìš”. ëª¨ë¥´ê² ì–´ìš”..

                -----

                [í•™ìŠµ ì •ë³´]
                - {text}

                -----

                [ê·œì¹™]
                - ì €ëŠ” í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
                - {pdf.name}ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
                - ì˜¤ì§ [í•™ìŠµ ì •ë³´]ì—ì„œ ë°°ìš´ ë‚´ìš©ë§Œ ë‹µí•˜ì„¸ìš”. 
                - ë§ˆì¹˜ ì–´ë¦° ì•„ì´ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¹œì ˆí•œ ì–´ì¡°ì™€ ê°„ë‹¨í•œ ë‹¨ì–´ë¡œ ì‘ì„±

                -----

                ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {pdf.name} ë™í™”ì— ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. 
                [ì˜ˆì™¸], [í•™ìŠµ ì •ë³´], [ê·œì¹™]ì€ ë‹µë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.
                AI Toryê°€ [í•™ìŠµì •ë³´]ì— ëŒ€í•œ ì •ë³´ë¡œ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
                ë‹¹ì‹ ì€ ì˜¤ì§ í•™ìŠµëœ ë‚´ìš©ë§Œ ì•Œë ¤ì£¼ë©° [ê·œì¹™]ì„ ë¬´ì¡°ê±´ ë”°ë¥´ëŠ” AI Toryì…ë‹ˆë‹¤.
                ì§ˆë¬¸í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ [í•™ìŠµ ì •ë³´]ë¡œ í•™ìŠµëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼í•©ë‹ˆë‹¤. 
                [ì˜ˆì‹œ ë¬¸ì¥]ê³¼ [í•™ìŠµ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ [í•™ìŠµ ì •ë³´]ì— ìˆëŠ” ì •ë³´ ë©”ì‹œì§€ë¥¼ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
            """

            user_question = prompt + query

            # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
            with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
                llm = OpenAI(
                    temperature=0.1,
                    model_name="gpt-3.5-turbo-16k",
                    top_p=1,
                    max_tokens=1000,
                )

                chain = load_qa_chain(llm=llm, chain_type="stuff") 
                response = chain.run(input_documents=docs, question=user_question)

                bot_message = response
                output = bot_message

                st.session_state.chat_past.append(query)
                st.session_state.chat_generated.append(output)

            if toggle_state:
                    # PDFê°€ ì—…ë¡œë“œë˜ì—ˆë‹¤ë©´ PDF ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤
                    gpt_prompt = [{
                        "role" : "system", 
                        "content" : f"""
                                    [Information] = {text}
                                    You are Beatrix Potter.
                                    You are draw a children's comic about {query}.
                                    Imagine the details.
                                    You Must be drawing for children's.
                                    """
                    }]
                    # gpt_prompt = [{
                    #         "role" : "system", 
                    #         "content" : f"You are a great painter that children like. Choose one character and organize the contents so that a fairy tale book can be created around that character. It is cute and draws pictures that children will like."
                    # }]
                    # gpt_prompt.append({
                    #         "role" : "user",
                    #         "content" :f"{pdf.name}, {text}"
                    # })

                    with st.spinner("í† ë¦¬ê°€ ë™í™”ë¥¼ ìƒìƒí•˜ê³  ìˆì–´ìš”.."):
                            gpt_response = openai.ChatCompletion.create(
                                model="gpt-3.5-turbo-16k",
                                messages=gpt_prompt,
                                max_tokens=50
                            )

                    pic_prompt = gpt_response["choices"][0]["message"]["content"]
                    dalle_prompt = pic_prompt

                    with st.spinner("í† ë¦¬ê°€ ë™í™”ì— ëŒ€í•´ì„œ ê·¸ë ¤ì¤„ê²Œìš”.."):
                        dallE_response = openai.Image.create(
                            prompt=dalle_prompt,
                            size= "1024x1024",
                            n=1
                        )
                    with col2:
                        img = st.image(dallE_response["data"][0]["url"], caption=pdf.name)
                        st.empty()
                        st.empty()
        

            # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥, tts í† ê¸€ë²„íŠ¼
            with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
                if st.session_state['chat_generated']:
                    for i in range(len(st.session_state['chat_generated']) - 1, -1, -1):
                        message(st.session_state['chat_past'][i], is_user=True, key=str(i) + '_user', avatar_style="thumbs", seed="Aneka")
                        message(st.session_state["chat_generated"][i], key=str(i), avatar_style="thumbs", seed="Felix")
                    
                    if tts_button:
                        tts = gTTS(text=output, lang='ko')
                        temp_file = NamedTemporaryFile(delete=False)
                        tts.save(temp_file.name)
                        playsound.playsound(temp_file.name)
                        temp_file.close()

            tory_firebase.add_firebase_chat(query, bot_message)
with tab2:
    if pdf is None:
        # ìŠ¤íŠ¸ë¦¼ë¦¿ ì•± í—¤ë” ì„¤ì •
        st.header("AI Toryì™€ ì—­í• ë†€ì´ í•˜ê¸°! ğŸ•¹ï¸")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì—­í• ì„ ì…ë ¥í•˜ê³  ì—­í• ë†€ì´ë¥¼ í•´ë´ìš”! ğŸ«µğŸ»')
        st.image(pdf_image_path)

    if pdf is not None:
        st.header(f"AIToryì™€ {pdf.name} ì—­í• ë†€ì´ ğŸ•¹ï¸")
        st.caption('AI Toryì—ê²Œ PDFë¥¼ í•™ìŠµì‹œí‚¤ê³ , ì—­í• ì„ ì…ë ¥í•˜ê³  ì—­í• ë†€ì´ë¥¼ í•´ë´ìš”! ğŸ«µğŸ»')
    if pdf is not None:
        user = ""
        ai = ""

        # ì‚¬ìš©ì ë° AI ì—­í•  ì…ë ¥
        with st.expander('ì—­í• ì„ ì •í•´ì£¼ì„¸ìš”!', expanded=True):
            user_input_col, ai_input_col = st.columns(2)
            user_input = user_input_col.text_input("ì‚¬ìš©ìì˜ ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš”:")
            ai_input = ai_input_col.text_input("AI Toryì˜ ì—­í• ì„ ì…ë ¥í•˜ì„¸ìš”:")

            if not user_input or not ai_input:
                st.warning("ì—­í• ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
        col1, col2, col3 = st.columns(3)

        if user_input and ai_input:  # ì—­í• ì´ ëª¨ë‘ ì…ë ¥ëœ ê²½ìš°ì—ë§Œ ì•„ë˜ ì»¨í…Œì´ë„ˆ í‘œì‹œ
            st.markdown("<hr>", unsafe_allow_html=True)

            # ìŠ¤íŠ¸ë¦¼ë¦¿ ì»¨í…Œì´ë„ˆ ìƒì„±
            with st.container():
                # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
                query = st.text_input("AIí† ë¦¬ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!", placeholder="Send a message", key="unique_key_for_text_input")

                # ê°€ë¡œë¡œ ì •ë ¬ëœ ë²„íŠ¼
                btn_col1, btn_col2, btn_col3 = st.columns(3)

                with btn_col1:
                    whisper_button = st.button("ğŸ™ï¸", help="ë§ˆì´í¬ë¥¼ ì—°ê²°í•´ì£¼ì„¸ìš”.", key="unique_key_for_whisper_button")

                with btn_col2:
                    tts_button = st.checkbox("ğŸ”Š",  value=True, help="AIí† ë¦¬ê°€ ë§í•´ì¤„ê²Œìš”.", key="unique_key_for_tts_button")

                with btn_col3:
                    toggle_state = st.checkbox('AI ğŸ¨', value=True, help="AIí† ë¦¬ê°€ ê·¸ë¦¼ì„ ê·¸ë ¤ì¤„ê²Œìš”.", key="unique_key_for_toggle_state")

                if whisper_button:
                    with st.spinner("ë§í•´ì£¼ì„¸ìš”! í† ë¦¬ê°€ ë“£ê³ ìˆì–´ìš”..."):
                        # PyAudioë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°
                        audio_data = []
                        p = pyaudio.PyAudio()
                        stream = p.open(format=pyaudio.paInt16, channels=1, rate=sample_rate, input=True, frames_per_buffer=1024)

                        # ì˜¤ë””ì˜¤ ë°ì´í„° ë…¹ìŒ
                        for i in range(0, int(sample_rate / 1024 * duration)):
                            audio_chunk = stream.read(1024)
                            audio_data.append(audio_chunk)

                    with st.spinner("í† ë¦¬ê°€ ë‹¤ ë“¤ì—ˆì–´ìš”..."):
                        # ë…¹ìŒ ì¤‘ì§€
                        stream.stop_stream()
                        stream.close()
                        p.terminate()

                        # ë…¹ìŒëœ ì˜¤ë””ì˜¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ì˜µì…˜)
                        audio_file = "recorded_audio.wav"
                        with wave.open(audio_file, "wb") as wf:
                            wf.setnchannels(1)
                            wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
                            wf.setframerate(sample_rate)
                            wf.writeframes(b"".join(audio_data))

                        # ìˆ˜ì •ëœ ë¶€ë¶„: ë…¹ìŒëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°
                        with open("recorded_audio.wav", "rb") as audio_file:
                            transcript = openai.Audio.transcribe("whisper-1", audio_file)
                            ko_response = transcript["text"].encode('utf-16').decode('utf-16')
                            query = ko_response
                if toggle_state is False: 
                    with col2:
                        st.empty()
                        st.empty()
                        st.empty()

                # PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                pdf_reader = PdfReader(pdf)
                text = ""
                for page in pdf_reader.pages:
                    text += page.extract_text()

                # í…ìŠ¤íŠ¸ë¥¼ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë‚˜ëˆ„ê¸°
                text_splitter = RecursiveCharacterTextSplitter(
                    chunk_size=1000,
                    chunk_overlap=200,
                    length_function=len
                )
                chunks = text_splitter.split_text(text=text)

                # PDF íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì €ì¥ì†Œ ìƒì„± ë˜ëŠ” ë¡œë“œ
                store_name = pdf.name[:-4]

                if os.path.exists(f"pdfs/{store_name}.pkl"):
                    with open(f"pdfs/{store_name}.pkl", "rb") as f:
                        VectorStore = pickle.load(f)
                    print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ìˆìŠµë‹ˆë‹¤!")
                else:
                    embedding = OpenAIEmbeddings()
                    VectorStore = FAISS.from_texts(chunks, embedding=embedding)
                    with open(f"pdfs/{store_name}.pkl", "wb") as f:
                        pickle.dump(VectorStore, f)
                    print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ì—†ìŠµë‹ˆë‹¤!")

                # ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
                if 'role_generated' not in st.session_state:
                    st.session_state['role_generated'] = []

                if 'role_past' not in st.session_state:
                    st.session_state['role_past'] = []

                if query:
                    # ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì ì ˆí•œ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
                    docs = VectorStore.similarity_search(query=query, k=3)
                    user = user_input
                    ai = ai_input
                    print(user)

                    # AI Toryì—ê²Œ ì „ë‹¬í•  ì§ˆë¬¸ ì‘ì„±
                    prompt = f"""
                    ë„ˆ = {user}
                    ë‚˜ = {ai}
                    ì‚¬ìš©ìì˜ ì§ˆë¬¸ = {query}

                    ----------------------------------------------------------------

                    [ì˜ˆì‹œë¬¸ì¥]
                    - ë‹¹ì‹ ì€ {user}ì´ê³ , ì €ëŠ” {ai}ì…ë‹ˆë‹¤.
                    - ê·¸ê²ƒì— ëŒ€í•œ ì •ë³´ëŠ” ëª¨ë¥´ê² ìŠµë‹ˆë‹¤.
                    
                    ----------------------------------------------------------------
                    [ê·œì¹™]
                    - {user}ì˜ {query}ì— {ai}ì˜ ë‹µë³€ì„ ìµœëŒ€ 3ì¤„ë¡œ í•´ë¼.
                    - {user}ì˜ {query}ì™€ {ai}ì˜ ê´€ê³„ë¥¼ ì´í•´í•˜ê³  ì ì ˆí•œ ë‹µë³€ì„ í•´ë¼.
                    - {user}ì™€ {ai}ì˜ ëŒ€í™”ë¥¼ ì§„í–‰í•˜ì„¸ìš”.
                    - {user}ê°€ ì§€ì •í•œ {ai}ì— ëŒ€í•œ ì§ˆë¬¸ì´ ì•„ë‹Œ ê²½ìš° ëª¨ë¥¸ë‹¤ê³  ëŒ€ë‹µí•´.
                    - ë‹¹ì‹ ì€ ì‚¬ìš©ìê°€ ì§€ì •í•œ ì—­í• ì¸ {ai}ì¸ ê²ƒ ì²˜ëŸ¼ ëŒ€ë‹µí•˜ê³  í–‰ë™í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
                    ----------------------------------------------------------------
                    ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {ai}ì— ëŒ€í•œ ë‚´ìš©ì…ë‹ˆë‹¤. [ì˜ˆì‹œ ë¬¸ì¥]ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´, ì—­í• ë†€ì´ì— ëŒ€ë‹µí•œ ë‚´ìš©ì…ë‹ˆë‹¤.
                    [ê·œì¹™]ì„ ë”°ë¥´ëŠ” {ai}ì…ë‹ˆë‹¤. {user}ì—ê²Œ {ai}ë§Œì˜ ë‹µë³€ì„ í•˜ì„¸ìš”.
                    ----------------------------------------------------------------
                    """

                    user_question = prompt + query

                    # AI Toryì˜ ì‘ë‹µ ìƒì„± ë° ì €ì¥
                    with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³ ìˆì–´ìš”..."):
                        llm = OpenAI(
                            temperature=0.1,
                            model_name="gpt-3.5-turbo-16k",
                            top_p=1,
                        )
                        chain = load_qa_chain(llm=llm, chain_type="refine")
                        response = chain.run(input_documents=docs, question=user_question)

                        bot_message = response
                        output = bot_message

                        st.session_state.role_past.append(query)
                        st.session_state.role_generated.append(output)

                    if toggle_state:
                            query = ""
                            # PDFê°€ ì—…ë¡œë“œë˜ì—ˆë‹¤ë©´ PDF ì²˜ë¦¬ë¥¼ í•©ë‹ˆë‹¤
                            gpt_prompt = [{
                                "role" : "system", 
                                "content" : f"""
                                            [Information] = {user_input}.
                                            You are Beatrix Potter.
                                            You are draw a children's comic draw pic about {query}.
                                            Imagine the details, No need text.
                                            You Must be drawing for children's.
                                            If say something that's not in the [Information], just draw your own picture of {query}
                                            """
                            }]    

                            with st.spinner("í† ë¦¬ê°€ ë™í™”ë¥¼ ìƒìƒí•˜ê³  ìˆì–´ìš”.."):
                                    gpt_response = openai.ChatCompletion.create(
                                        model="gpt-3.5-turbo-16k",
                                        messages=gpt_prompt,
                                        max_tokens=50
                                    )

                            pic_prompt = gpt_response["choices"][0]["message"]["content"]
                            dalle_prompt = pic_prompt

                            with st.spinner("í† ë¦¬ê°€ ë™í™”ì— ëŒ€í•´ì„œ ê·¸ë ¤ì¤„ê²Œìš”.."):
                                dallE_response = openai.Image.create(
                                    prompt=dalle_prompt,
                                    size= "1024x1024",
                                    n=1
                                )
                            with col2:
                                img = st.image(dallE_response["data"][0]["url"], caption=pdf.name)
                                st.empty()
                                st.empty()
                    # ëŒ€í™” ê¸°ë¡ ë° ìŒì„± ì¶œë ¥
                    with st.spinner("í† ë¦¬ê°€ ë§í•˜ê³ ìˆì–´ìš”..."):
                        if st.session_state['role_generated']:
                            for i in range(len(st.session_state['role_generated']) - 1, -1, -1):
                                message(st.session_state["role_generated"][i], key=str(i), avatar_style="thumbs", seed="Felix")
                                message(st.session_state['role_past'][i], is_user=True, key=str(i) + '_user', avatar_style="thumbs", seed="Aneka")

                            if tts_button:
                                query = ""
                                tts = gTTS(text=output, lang='ko')
                                temp_file = NamedTemporaryFile(delete=False)
                                tts.save(temp_file.name)
                                playsound.playsound(temp_file.name)
                                temp_file.close()

                        tory_firebase.add_firebase_role(query, bot_message)