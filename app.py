import os
#  streamlit = Pythonì—ì„œ GUI ìƒì„±
import streamlit as st
import pickle # íŒŒì´ì¬ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” ê¸°ëŠ¥
import playsound

from tempfile import NamedTemporaryFile

from gtts import gTTS

from streamlit_extras.add_vertical_space import add_vertical_space
from streamlit_chat import message

# PyPDF2 = streamlitì˜ PDF ì—…ë¡œë“œë¥¼ ì½ê¸° ìœ„í•´ 
from PyPDF2 import PdfReader

# langchain.text_splitter = PyPDF2ì˜ í…ìŠ¤íŠ¸ë¥¼ chunksë¡œ ë‚˜ëˆ”
from langchain.text_splitter import RecursiveCharacterTextSplitter
# openAIì˜ embedding = ê³„ì‚°í•˜ê³  ë°˜í™˜
from langchain.embeddings.openai import OpenAIEmbeddings
# VectorStore = FAISS, Chroma X = VectorStoreì—ì„œ duckdb.DuckDBPyConnection ì ‘ê·¼ ë¶ˆê°€ëŠ¥
from langchain.vectorstores import FAISS
from dotenv import load_dotenv # OPEN_API_KEY
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain # ë‹µë³€

# ----------------------

# ìˆ˜ì§ ì‚¬ì´ë“œë°”
with st.sidebar:
    st.title('ğŸ¤– LLM AI Tory')
    st.markdown('''
    ## About
    AI Toryì™€ í•¨ê»˜ ë†€ì•„ìš”! ğŸ˜€
    - [AI Toryì™€ ëŒ€í™”í•˜ê¸°](https://streamlit.io/)
    - [ì£¼ì¸ê³µê³¼ ëŒ€í™”í•˜ê¸°](https://streamlit.io/)
    - [ê·¸ë¦¼ ê·¸ë¦¬ê¸°](https://python.langchain.com/)
    - [OpenAI](https://platform.openai.com/docs/models) LLM model
    ''')
    add_vertical_space(5)
    st.write('Project [AI Tory](https://python.langchain.com/)')
# ìˆ˜ì§ ì‚¬ì´ë“œë°”

# ----------------------


# ----------------------
def main():
    load_dotenv()

    st.header("AI Toryì™€ ëŒ€í™”í•˜ê¸°! ğŸ’¬")    

    # upload PDF / íŒŒì¼ë‹¹ 200MB ì œí•œ
    pdf = st.file_uploader("AI Toryì—ê²Œ í•™ìŠµí•  ë™í™” PDFë¥¼ Upload í•´ì£¼ì„¸ìš”", type='pdf', key='pdf')

    # ì—…ë¡œë“œê°€ ì—†ì„ì‹œ None ë°©ì§€ ifë¬¸
    if pdf is not None:

        query = st.text_input("AIí† ë¦¬ì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!",)
        AIttsButton = st.button("ğŸ”Š")
        pdf_reader = PdfReader(pdf)
        text = ""

        for page in pdf_reader.pages:
            text += page.extract_text()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size = 1000,
            chunk_overlap = 200,
            length_function = len
        )
        chunks = text_splitter.split_text(text = text)

        store_name = pdf.name[:-4]

        if os.path.exists(f"pdfs/{store_name}.pkl"):
            with open(f"pdfs/{store_name}.pkl", "rb") as f:
                VectorStore = pickle.load(f)
            print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ìˆìŠµë‹ˆë‹¤!")
        else :
            embedding = OpenAIEmbeddings()
            VectorStore = FAISS.from_texts(chunks, embedding = embedding)
            with open(f"pdfs/{store_name}.pkl", "wb") as f:
                pickle.dump(VectorStore, f)
            print("í•´ë‹¹ PDFëŠ” ì €ì¥ì†Œì— ì—†ìŠµë‹ˆë‹¤!")

        if 'generated' not in st.session_state:
            st.session_state['generated'] = []
        
        if 'past' not in st.session_state:
            st.session_state['past'] = []

        if query:
            docs = VectorStore.similarity_search(query=query, k=3)

            prompt ="""
                [ì˜ˆì™¸]
                - ì €ëŠ” '{pdf.name}'ë¼ëŠ” ë™í™”ë¥¼ í•™ìŠµí–ˆì–´ìš”. {query}ì€ ëª¨ë¥´ê² ì–´ìš”..

                -----

                [í•™ìŠµ ì •ë³´]
                - {text}

                -----

                [ê·œì¹™]
                - [í•™ìŠµ ì •ë³´]ì— ì—†ëŠ” ì§ˆë¬¸ì¸ ê²½ìš° [ì˜ˆì™¸]ë¡œ ëŒ€ë‹µí•œë‹¤.
                - '{pdf.name}'ë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
                - ì˜¤ì§ [í•™ìŠµ ì •ë³´]ì—ì„œ ë°°ìš´ ë‚´ìš©ë§Œ ë‹µí•˜ì„¸ìš”. 
                - ë§ˆì¹˜ ì–´ë¦° ì•„ì´ì™€ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ì¹œì ˆí•œ ì–´ì¡°ì™€ ê°„ë‹¨í•œ ë‹¨ì–´ë¡œ ì‘ì„±

                -----

                ìœ„ ì •ë³´ëŠ” ëª¨ë‘ {pdf.name} ë™í™”ì— ê´€ë ¨ëœ ë‚´ìš©ì…ë‹ˆë‹¤. 
                [ì˜ˆì™¸], [í•™ìŠµ ì •ë³´], [ê·œì¹™]ì€ ë‹µë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.
                AI Toryê°€ [í•™ìŠµì •ë³´ì— ëŒ€í•œ ì •ë³´ë¡œ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
                ë‹¹ì‹ ì€ ì˜¤ì§ í•™ìŠµëœ ë‚´ìš©ë§Œ ì•Œë ¤ì£¼ë©° [ê·œì¹™]ì„ ë¬´ì¡°ê±´ ë”°ë¥´ëŠ” AI Toryì…ë‹ˆë‹¤.
                ì§ˆë¬¸í•˜ëŠ” ì‚¬ìš©ìì—ê²Œ [í•™ìŠµ ì •ë³´]ë¡œ í•™ìŠµëœ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•´ì•¼í•©ë‹ˆë‹¤. 
                [ì˜ˆì‹œ ë¬¸ì¥]ê³¼ [í•™ìŠµ ì •ë³´]ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ [í•™ìŠµ ì •ë³´]ì— ìˆëŠ” ì •ë³´ ë©”ì‹œì§€ë¥¼ ì°½ì˜ì ì¸ ë‹µë³€ì„ í•©ë‹ˆë‹¤.
            """

            user_question = prompt + query

            with st.spinner("í† ë¦¬ê°€ ìƒê°í•˜ê³  ë§í•´ì¤„ê²Œìš”!"):
                llm = OpenAI(
                    temperature=0.5,
                    model_name="gpt-3.5-turbo-16k",
                    max_tokens=600,
                    top_p=1)

                chain = load_qa_chain(llm=llm, chain_type="stuff")
                response = chain.run(input_documents=docs, question=user_question)

                bot_message = response
                output = bot_message

                st.session_state.past.append(query)
                st.session_state.generated.append(output)




            with st.spinner("í† ë¦¬ê°€ ë§í•´ì¤„ê²Œìš”!"):
                # ë§Œì•½ 'generated'ë¼ëŠ” ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜ê°€ ì¡´ì¬í•œë‹¤ë©´
                if st.session_state['generated']:
                # 'generated' ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ìš”ì†Œë¶€í„° ì—­ìˆœìœ¼ë¡œ ë°˜ë³µ
                    for i in range(len(st.session_state['generated']) - 1, -1, -1):
                        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ í‘œì‹œ (ì„¸ì…˜ ìƒíƒœì˜ 'past' ë³€ìˆ˜ë¥¼ ì‚¬ìš©)
                        message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
                        # ìƒì„±ëœ ë©”ì‹œì§€ë¥¼ í‘œì‹œ (ê³ ìœ í•œ í‚¤ ê°’ì„ ì„¤ì •í•˜ì—¬ ì¤‘ë³µì„ í”¼í•¨)
                        message(st.session_state["generated"][i], key=str(i))

                if AIttsButton:
                    # gTTSë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
                    tts = gTTS(text=output, lang='ko')  # 'ko'ëŠ” í•œêµ­ì–´
                    temp_file = NamedTemporaryFile(delete=False)
                    tts.save(temp_file.name)

                    # ì„ì‹œ íŒŒì¼ì„ ì¬ìƒ
                    playsound.playsound(temp_file.name)
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    temp_file.close()


                        
if __name__ == "__main__":
    main()
